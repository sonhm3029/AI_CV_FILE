{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2b562c519342>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "pregnant    0\n",
       "glucose     0\n",
       "bp          0\n",
       "skin        0\n",
       "insulin     0\n",
       "bmi         0\n",
       "pedigree    0\n",
       "age         0\n",
       "label       0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "col_names = ['pregnant', 'glucose', 'bp', 'skin', 'insulin', 'bmi', 'pedigree', 'age', 'label']\n",
    "# load dataset\n",
    "pima = pd.read_csv(\"pima-indians-diabetes.csv\", header = None, names=col_names)\n",
    "pima.head()\n",
    "pima.shape\n",
    "pima.isna().sum() #check for missing values and also the data types \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset in features and target variable\n",
    "X = pima.drop(columns = ['label']) # Features\n",
    "y_label = pima['label'].values.reshape(X.shape[0],1) # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain,Xtest,ytrain,ytest= train_test_split(X, y_label, test_size= 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "sc.fit(Xtrain)\n",
    "Xtrain = sc.transform(Xtrain)\n",
    "Xtest = sc.transform(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    def __init__(self, layers = [8,5,1], learning_rate = 0.001, iterations = 1000):\n",
    "        self.params = {}\n",
    "        self.learning_rate = learning_rate\n",
    "        self.iterations = iterations \n",
    "        self.loss = []\n",
    "        self.sample_size = None\n",
    "        self.layers = layers\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "    def init_weights(self):\n",
    "        np.random.seed(1)\n",
    "        self.params[\"W1\"] = np.random.randn(self.layers[0], self.layers[1])\n",
    "        self.params[\"b1\"] = np.random.randn(self.layers[1],)\n",
    "        self.params[\"W2\"] = np.random.randn(self.layers[1], self.layers[2])\n",
    "        self.params[\"b2\"] = np.random.randn(self.layers[2],)\n",
    "    def entropy_loss(self, y, yhat):\n",
    "        nsample = len(y)\n",
    "        loss = -1/nsample * (np.sum(np.multiply(np.log(yhat),y) + np.multiply((1-y), np.log(1-yhat))))\n",
    "        return loss\n",
    "    def relu(self,Z):\n",
    "        return np.maximum(0,Z)\n",
    "    def sigmoid(self, x):\n",
    "        return 1/ (1 + np.exp(-x))\n",
    "    def forward_propagation(self):\n",
    "        Z1 = self.X.dot(self.params['W1']) + self.params['b1']\n",
    "        A1 = self.sigmoid(Z1)\n",
    "        Z2 = A1.dot(self.params['W2']) + self.params['b2']\n",
    "        yhat = self.sigmoid(Z2)\n",
    "        loss = self.entropy_loss(self.y, yhat)\n",
    "        \n",
    "        self.params['Z1'] = Z1\n",
    "        self.params['Z2'] = Z2\n",
    "        self.params['A1'] = A1\n",
    "        \n",
    "        return yhat,loss\n",
    "    def back_propagation(self, yhat):\n",
    "        \n",
    "        def dRelu(x):\n",
    "            x[x<=0] = 0\n",
    "            x[x>0] = 1\n",
    "            return x\n",
    "        def dSigmoid(x):\n",
    "            return x*(1-x)\n",
    "        \n",
    "        dL_yhat = -(np.divide(self.y,yhat)) - np.divide((1-self.y),(1-yhat))\n",
    "        dL_sig = yhat * (1-yhat)\n",
    "        dL_z2 = dL_yhat * dL_sig\n",
    "        \n",
    "        dL_A1 = dL_z2.dot(self.params['W2'].T)\n",
    "        dL_w2 = self.params['A1'].T.dot(dL_z2)\n",
    "        dL_b2 = np.sum(dL_z2, axis = 0) #\n",
    "        \n",
    "        dL_z1 = dL_A1 * dSigmoid(self.params['Z1'])\n",
    "        dL_w1 = self.X.T.dot(dL_z1)\n",
    "        dL_b1 = np.sum(dL_z1, axis = 0)\n",
    "        \n",
    "        #update the weights and bias \n",
    "        self.params['W1'] -= self.learning_rate * dL_w1\n",
    "        self.params['W2'] -= self.learning_rate * dL_w2\n",
    "        self.params['b1'] -= self.learning_rate * dL_b1\n",
    "        self.params['b2'] -= self.learning_rate * dL_b2\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Trains the neural network using the specified data and labels\n",
    "    \n",
    "        self.X = X \n",
    "        self.y = y\n",
    "        self.init_weights()\n",
    "    \n",
    "        for i in range(self.iterations):\n",
    "            yhat, loss = self.forward_propagation()\n",
    "            self.back_propagation(yhat)\n",
    "            self.loss.append(loss)\n",
    "    \n",
    "    def predict(self,X):\n",
    "        #Predict on a test data\n",
    "        Z1 = X.dot(self.params['W1']) + self.params['b1']\n",
    "        A1 = self.sigmoid(Z1)\n",
    "        Z2 = A1.dot(self.params['W2']) + self.params['b2']\n",
    "        pred = self.sigmoid(Z2)\n",
    "        return np.round(pred)\n",
    "    \n",
    "    def acc(self, y, yhat):\n",
    "        #Calculates the accuracy between the predicted value and the truth labels\n",
    "        \n",
    "        acc = int(sum(y==yhat) / len(y) * 100)\n",
    "        return acc\n",
    "    \n",
    "    def plot_loss(self):\n",
    "        #Plot the loss curve \n",
    "        \n",
    "        plt.plot(self.loss)\n",
    "        plt.xlabel(\"Iterations\")\n",
    "        plt.ylabel(\"logloss\")\n",
    "        plt.title(\"Loss curve for training\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'NeuralNetwork' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-6b41938c71e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNeuralNetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'NeuralNetwork' is not defined"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork()\n",
    "nn.fit(Xtrain, ytrain)\n",
    "nn.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = nn.predict(Xtrain)\n",
    "test_pred = nn.predict(Xtest)\n",
    "\n",
    "print(\"Train accuracy is {}\".format(nn.acc(ytrain, train_pred)))\n",
    "print(\"Test accuracy is {}\".format(nn.acc(ytest, test_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "interpreter": {
   "hash": "be7ecbbb0109f7b5d60c057de81f4c646c3fab511dd9c096ed6a5153f8b874d3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}